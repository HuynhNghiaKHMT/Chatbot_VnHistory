{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec270da3",
   "metadata": {},
   "source": [
    "### Imports Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c593a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Weaviate Imports ---\n",
    "import os\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "from weaviate.classes.query import MetadataQuery\n",
    "from weaviate.collections import Collection\n",
    "from weaviate.classes.query import Filter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- LangChain Imports ---\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "from typing import List\n",
    "\n",
    "# --- Th√™m Import Predictor ---\n",
    "from document_classification.predict import DocumentPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06c4ab",
   "metadata": {},
   "source": [
    "### Setup Reciprocal Rank Fusion (RRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√†m RRF ƒë√£ ƒëi·ªÅu ch·ªânh ƒë·ªÉ ho·∫°t ƒë·ªông v·ªõi LangChain (h·ª£p nh·∫•t c√°c ƒë·ªëi t∆∞·ª£ng Weaviate)\n",
    "def reciprocal_rank_fusion(results, k=60):\n",
    "    fused_scores = {}\n",
    "    for result_list in results:\n",
    "        for rank, obj in enumerate(result_list):\n",
    "            uuid = str(obj.uuid)\n",
    "            score = 1.0 / (k + rank + 1)\n",
    "            \n",
    "            if uuid not in fused_scores:\n",
    "                fused_scores[uuid] = {\"score\": 0.0, \"object\": obj}\n",
    "            fused_scores[uuid][\"score\"] += score\n",
    "            \n",
    "    sorted_fused_results = sorted(\n",
    "        fused_scores.values(), \n",
    "        key=lambda x: x[\"score\"], \n",
    "        reverse=True\n",
    "    )\n",
    "    return sorted_fused_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1d3b9",
   "metadata": {},
   "source": [
    "### Custom HybridRetriever (Vector + BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Retriever ƒë·ªÉ th·ª±c hi·ªán Hybrid Search (Vector + BM25)\n",
    "class HybridRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever t√πy ch·ªânh s·ª≠ d·ª•ng Weaviate near_vector v√† bm25.\"\"\"\n",
    "    history_collection: Collection \n",
    "    embed_model: SentenceTransformer\n",
    "    k: int = 4 # S·ªë l∆∞·ª£ng t√†i li·ªáu s·∫Ω tr·∫£ v·ªÅ cho LLM\n",
    "\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:\n",
    "\n",
    "        # 0. PH√ÇN LO·∫†I T√ÄI LI·ªÜU ===\n",
    "        predicted_period = DocumentPredictor.predict(query)\n",
    "        print(f\"\\n=== [DEBUG 0] CH·ª¶ ƒê·ªÄ D·ª∞ ƒêO√ÅN: {predicted_period} ===\")\n",
    "        where_filter = Filter.by_property(\"period\").equal(predicted_period)\n",
    "        \n",
    "        # 1. T·∫°o Vector t·ª´ m√¥ h√¨nh c·ª•c b·ªô\n",
    "        query_vector = self.embed_model.encode(query).tolist() \n",
    "\n",
    "        # 2. Vector Search (Ng·ªØ nghƒ©a)\n",
    "        print(\"\\n=== [DEBUG 1] K·∫æT QU·∫¢ TRUY XU·∫§T NG·ªÆ NGHƒ®A (VECTOR SEARCH) ===\")\n",
    "        vector_results = self.history_collection.query.near_vector(\n",
    "            near_vector=query_vector,\n",
    "            limit=self.k, # L·∫•y nhi·ªÅu k·∫øt qu·∫£ h∆°n cho RRF\n",
    "            return_properties=[\"context\", \"period\"],\n",
    "            return_metadata=MetadataQuery(distance=True),\n",
    "            # filters=where_filter # T√™n tham s·ªë l√† 'filters'\n",
    "        )\n",
    "        for i, obj in enumerate(vector_results.objects):\n",
    "            context = obj.properties.get(\"context\", \"\")\n",
    "            distance = obj.metadata.distance if obj.metadata and obj.metadata.distance else \"N/A\"\n",
    "            print(f\"[{i+1}] (Distance: {distance:.4f}) [UUID: {obj.uuid}] - Context: {context[:100]}...\")\n",
    "\n",
    "\n",
    "        # 3. BM25 Search (T·ª´ kh√≥a)\n",
    "        print(\"\\n=== [DEBUG 2] K·∫æT QU·∫¢ TRUY XU·∫§T T·ª™ KH√ìA (BM25 SEARCH) ===\")\n",
    "        bm25_results = self.history_collection.query.bm25(\n",
    "            query=query,\n",
    "            limit=self.k, # L·∫•y nhi·ªÅu k·∫øt qu·∫£ h∆°n\n",
    "            return_properties=[\"context\", \"period\"],\n",
    "            return_metadata=MetadataQuery(),\n",
    "            # filters=where_filter # T√™n tham s·ªë l√† 'filters'\n",
    "        )\n",
    "        for i, obj in enumerate(bm25_results.objects):\n",
    "            context = obj.properties.get(\"context\", \"\")\n",
    "            print(f\"[{i+1}] [UUID: {obj.uuid}] - Context: {context[:100]}...\")\n",
    "\n",
    "\n",
    "        # 4. H·ª£p nh·∫•t b·∫±ng RRF\n",
    "        fused_objects = reciprocal_rank_fusion([\n",
    "            vector_results.objects,\n",
    "            bm25_results.objects\n",
    "        ], k=60)\n",
    "        \n",
    "        print(\"\\n=== [DEBUG 3] K·∫æT QU·∫¢ H·ª¢P NH·∫§T RRF (TOP 8) ===\")\n",
    "        # In ra 8 k·∫øt qu·∫£ h√†ng ƒë·∫ßu sau khi h·ª£p nh·∫•t ƒë·ªÉ xem RRF ho·∫°t ƒë·ªông\n",
    "        for i, item in enumerate(fused_objects[:4]):\n",
    "            obj = item[\"object\"]\n",
    "            context = obj.properties.get(\"context\", \"\")\n",
    "            score = item[\"score\"]\n",
    "            print(f\"[{i+1}] (RRF Score: {score:.4f}) [UUID: {obj.uuid}] - Context: {context[:100]}...\")\n",
    "\n",
    "        # 5. Chuy·ªÉn ƒë·ªïi c√°c ƒë·ªëi t∆∞·ª£ng Weaviate th√†nh Document c·ªßa LangChain\n",
    "        # Ch·ªâ l·∫•y top K (4 documents)\n",
    "        documents = []\n",
    "        for item in fused_objects[:self.k]:\n",
    "            obj = item[\"object\"]\n",
    "            # Chuy·ªÉn ƒë·ªïi thu·ªôc t√≠nh Weaviate th√†nh metadata c·ªßa LangChain Document\n",
    "            metadata = {\n",
    "                \"period\": obj.properties.get(\"period\", \"N/A\"),\n",
    "                \"source_uuid\": str(obj.uuid),\n",
    "                \"rrf_score\": item[\"score\"]\n",
    "            }\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=obj.properties.get(\"context\", \"\"),\n",
    "                    metadata=metadata\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n<<< TR·∫¢ V·ªÄ {len(documents)} DOCUMENT CHO LLM (ƒê√£ L·ªçc theo {predicted_period})>>>\")\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042daaa6",
   "metadata": {},
   "source": [
    "### Setup Environment Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb910cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫£i Bi·∫øn M√¥i tr∆∞·ªùng v√† Kh·ªüi t·∫°o Model\n",
    "load_dotenv() \n",
    "\n",
    "# L·∫•y th√¥ng tin k·∫øt n·ªëi\n",
    "WEAVIATE_URL = os.environ.get(\"WEAVIATE_URL\")\n",
    "WEAVIATE_API_KEY = os.environ.get(\"WEAVIATE_API_KEY\")\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\") \n",
    "COLLECTION_NAME = \"History\" \n",
    "\n",
    "# S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh c·ª•c b·ªô c·ªßa b·∫°n\n",
    "LOCAL_MODEL_PATH = os.environ.get(\"EMBEDDING_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6621c936",
   "metadata": {},
   "source": [
    "### Run Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = None\n",
    "try:\n",
    "    # Kh·ªüi t·∫°o m√¥ h√¨nh nh√∫ng c·ª•c b·ªô\n",
    "    embed_model = SentenceTransformer(LOCAL_MODEL_PATH)\n",
    "\n",
    "    # 2. Thi·∫øt l·∫≠p K·∫øt n·ªëi Weaviate\n",
    "    client = weaviate.connect_to_weaviate_cloud(\n",
    "        cluster_url=WEAVIATE_URL,\n",
    "        auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n",
    "    )\n",
    "    \n",
    "    if not client.is_ready():\n",
    "        raise ConnectionError(\"Weaviate client is not ready.\")\n",
    "    \n",
    "    history_collection = client.collections.get(COLLECTION_NAME)\n",
    "\n",
    "    # 3. Kh·ªüi t·∫°o LLM (S·ª≠ d·ª•ng Gemini)\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        google_api_key=GEMINI_API_KEY,\n",
    "        temperature=0.1,\n",
    "    )\n",
    "\n",
    "    # 4. Kh·ªüi t·∫°o Custom Hybrid Retriever\n",
    "    retriever = HybridRetriever(\n",
    "        history_collection=history_collection,\n",
    "        embed_model=embed_model,\n",
    "        k=4 # LLM s·∫Ω nh·∫≠n 4 context documents t·ª´ Hybrid Search\n",
    "    )\n",
    "\n",
    "    # 5. Thi·∫øt l·∫≠p Prompt (H∆∞·ªõng d·∫´n LLM)\n",
    "    template = \"\"\"\n",
    "    B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh v·ªÅ L·ªãch s·ª≠ Vi·ªát Nam. \n",
    "    H√£y s·ª≠ d·ª•ng c√°c ƒëo·∫°n ng·ªØ c·∫£nh (Context) ƒë∆∞·ª£c cung c·∫•p d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch chi ti·∫øt v√† trung th·ª±c. \n",
    "    \n",
    "    Ng·ªØ c·∫£nh: {context}\n",
    "\n",
    "    C√¢u h·ªèi: {question}\n",
    "\n",
    "    C√¢u tr·∫£ l·ªùi chi ti·∫øt:\n",
    "    \"\"\"\n",
    "    RAG_PROMPT_CUSTOM = PromptTemplate.from_template(template)\n",
    "\n",
    "    # N·∫øu th√¥ng tin trong ng·ªØ c·∫£nh kh√¥ng ƒë·ªß ho·∫∑c kh√¥ng li√™n quan, h√£y tr·∫£ l·ªùi \"T√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p.\"\n",
    "\n",
    "    # 6. T·∫°o RetrievalQA Chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\", \n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": RAG_PROMPT_CUSTOM}\n",
    "    )\n",
    "\n",
    "    # 7. Ch·∫°y Truy v·∫•n RAG\n",
    "    H·ªéI = \"Chi·∫øn d·ªãch ƒëi·ªán bi√™n ph·ªß x·∫£y ra v√†o nƒÉm n√†o?\"\n",
    "    \n",
    "    print(f\"\\n‚ùì C√¢u h·ªèi: {H·ªéI}\")\n",
    "    print(\"---------------------------------------\")\n",
    "    \n",
    "    # S·ª≠ d·ª•ng .invoke()\n",
    "    result = qa_chain.invoke({\"query\": H·ªéI}) \n",
    "\n",
    "    # 8. In k·∫øt qu·∫£\n",
    "    print(\"\\n---------------------------------------\")\n",
    "    print(\"ü§ñ C√¢u tr·∫£ l·ªùi t·ª´ Gemini:\")\n",
    "    print(result[\"result\"])\n",
    "    print(\"\\nüìö Ngu·ªìn Context ƒë∆∞·ª£c s·ª≠ d·ª•ng (ƒê∆∞·ª£c ch·ªçn b·ªüi RRF):\")\n",
    "    for doc in result[\"source_documents\"]:\n",
    "        print(f\"- [Ngu·ªìn: {doc.metadata.get('period', 'N/A')}, RRF Score: {doc.metadata.get('rrf_score', 0.0):.4f}] {doc.page_content[:100]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh RAG: {e}\")\n",
    "\n",
    "finally:\n",
    "    if client and client.is_connected():\n",
    "        client.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
